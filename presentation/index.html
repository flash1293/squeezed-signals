<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Squeezed Signals: Observability Data Compression</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reset.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/theme/black.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/monokai.css">
    <style>
        .reveal h1, .reveal h2, .reveal h3 {
            text-transform: none;
        }
        .reveal section {
            text-align: left;
        }
        .reveal section.center {
            text-align: center;
        }
        .reveal pre {
            width: 100%;
            font-size: 0.5em;
        }
        .reveal code {
            font-family: 'Courier New', monospace;
        }
        .reveal table {
            font-size: 0.7em;
        }
        .reveal .highlight {
            color: #42affa;
            font-weight: bold;
        }
        .reveal .success {
            color: #5cb85c;
        }
        .reveal .warning {
            color: #f0ad4e;
        }
        .reveal .danger {
            color: #d9534f;
        }
        .comparison-table {
            margin: 20px auto;
        }
        .comparison-table th {
            background-color: #42affa;
        }
        .comparison-table td {
            text-align: center;
        }
        .emoji {
            font-size: 1.5em;
        }
        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .box {
            border: 2px solid #42affa;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
        }
        .small-text {
            font-size: 0.8em;
        }
        .formula {
            background: #1a1a1a;
            padding: 10px;
            border-left: 4px solid #42affa;
            margin: 10px 0;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">

            <!-- Title Slide -->
            <section class="center">
                <h1>üóúÔ∏è Squeezed Signals</h1>
                <h3>The Evolution of Observability Data Storage</h3>
                <p style="margin-top: 50px;">A deep dive into compressing metrics, logs, and traces</p>
                <p class="small-text" style="margin-top: 50px;">Press <kbd>Space</kbd> to navigate ‚Üí</p>
            </section>

            <!-- Agenda -->
            <section>
                <h2>üìã Agenda (45 minutes)</h2>
                <ol>
                    <li><strong>Introduction</strong> - The observability data explosion (5 min)</li>
                    <li><strong>Metrics</strong> - Time-series compression (12 min)</li>
                    <li><strong>Logs</strong> - Structured text compression (12 min)</li>
                    <li><strong>Traces</strong> - Distributed execution compression (10 min)</li>
                    <li><strong>Reality Check</strong> - Trade-offs & practical considerations (6 min)</li>
                </ol>
            </section>

            <!-- PART 1: INTRODUCTION -->
            <section class="center">
                <h1>Part 1: Introduction</h1>
                <p>The Observability Data Problem</p>
            </section>

            <section>
                <h2>üî≠ What is Observability?</h2>
                <div class="box">
                    <p><strong>Observability</strong> = Understanding what's happening inside your systems</p>
                </div>
                <div class="two-column">
                    <div>
                        <h4>üìä Metrics</h4>
                        <p class="small-text">Numerical measurements</p>
                        <ul class="small-text">
                            <li>CPU usage: 72.3%</li>
                            <li>Requests/sec: 1,247</li>
                            <li>Memory: 4.2 GB</li>
                        </ul>
                    </div>
                    <div>
                        <h4>üìù Logs</h4>
                        <p class="small-text">Text event records</p>
                        <ul class="small-text">
                            <li>"User logged in"</li>
                            <li>"Error: Connection timeout"</li>
                            <li>"Request processed in 42ms"</li>
                        </ul>
                    </div>
                </div>
                <div style="margin-top: 20px;">
                    <h4>üîç Traces</h4>
                    <p class="small-text">Distributed request flows across microservices</p>
                    <p class="small-text">api-gateway ‚Üí user-service ‚Üí auth-service ‚Üí database</p>
                </div>
            </section>

            <section>
                <h2>üéØ Project Goals</h2>
                <div class="box">
                    <h4>Primary Goal</h4>
                    <p>Demonstrate <span class="highlight">progressive compression techniques</span> from naive approaches to production-grade algorithms</p>
                </div>
                <div class="two-column" style="margin-top: 20px;">
                    <div class="box success">
                        <h4>‚úÖ What We'll Cover</h4>
                        <ul class="small-text">
                            <li>Lossless compression</li>
                            <li>Domain-specific techniques</li>
                            <li>Real-world algorithms</li>
                            <li>Measurable improvements</li>
                        </ul>
                    </div>
                    <div class="box warning">
                        <h4>‚ö†Ô∏è Important Note</h4>
                        <ul class="small-text">
                            <li>Focus: Storage size</li>
                            <li>Not covered deeply: Query speed, Ingest CPU</li>
                            <li>These matter in production!</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section>
                <h2>üìä Overview</h2>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Signal Type</th>
                            <th>Starting Size</th>
                            <th>Key Challenge</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>üìä Metrics</td>
                            <td>80.8 MB NDJSON</td>
                            <td>Temporal patterns in numbers</td>
                        </tr>
                        <tr>
                            <td>üìù Logs</td>
                            <td>72.7 MB Plain Text</td>
                            <td>Repeated structure with variables</td>
                        </tr>
                        <tr>
                            <td>üîç Traces</td>
                            <td>71.1 MB NDJSON</td>
                            <td>Parent-child relationships</td>
                        </tr>
                    </tbody>
                </table>
                <p class="small-text" style="text-align: center; margin-top: 30px;">
                    Each uses different strategies tailored to data characteristics
                </p>
            </section>

            <!-- PART 2: METRICS -->
            <section class="center">
                <h1>Part 2: Metrics</h1>
                <p>üìä Time-Series Compression Journey</p>
            </section>

            <section>
                <h2>What Are Metrics?</h2>
                <div class="box">
                    <h4>Time-series numerical data</h4>
                    <p class="small-text">Regular intervals, labeled dimensions</p>
                </div>
                <pre><code class="language-json">{
  "metric_name": "system.cpu.user",
  "labels": {
    "host": "server-01",
    "datacenter": "us-west-1"
  },
  "timestamp": 1698000000,
  "value": 72.34567
}</code></pre>
                <p class="small-text"><strong>Key characteristics:</strong></p>
                <ul class="small-text">
                    <li>Timestamps are regular (e.g., every 60 seconds)</li>
                    <li>Values change slowly (temporal locality)</li>
                    <li>Labels repeat across many series</li>
                </ul>
            </section>

            <section>
                <h2>üìà Metrics: Progressive Journey</h2>
                <div class="box">
                    <h4>We'll explore 6 compression phases</h4>
                    <p class="small-text">Each phase builds on the previous, demonstrating how domain knowledge compounds with general techniques</p>
                </div>
                <div class="box" style="margin-top: 20px;">
                    <p class="small-text"><strong>Starting point:</strong> 80.8 MB NDJSON</p>
                    <p class="small-text">Each phase will reveal new techniques and improvements</p>
                </div>
            </section>

            <!-- Phase 1: NDJSON Baseline -->
            <section>
                <h2>Phase 1: NDJSON Baseline (80.8 MB, 1.0x)</h2>
                <div class="box">
                    <h4>Newline-Delimited JSON</h4>
                </div>
                <pre><code class="language-json">{"metric_name":"system.cpu.user","labels":{"host":"server-01","datacenter":"us-west-1"},"timestamp":1698000000,"value":72.34567}
{"metric_name":"system.cpu.user","labels":{"host":"server-01","datacenter":"us-west-1"},"timestamp":1698000060,"value":72.34589}
{"metric_name":"system.cpu.user","labels":{"host":"server-01","datacenter":"us-west-1"},"timestamp":1698000120,"value":72.34612}
</code></pre>
                <p class="small-text"><strong>Observations:</strong></p>
                <ul class="small-text">
                    <li>Text-based, human-readable format</li>
                    <li>Repeated keys: "metric_name", "labels", "timestamp", "value"</li>
                    <li>Same metric name and labels repeated thousands of times</li>
                    <li>Timestamps are sequential (60 second intervals)</li>
                    <li>Values change slowly (temporal locality)</li>
                </ul>
            </section>

            <!-- Phase 2: CBOR Binary -->
            <section>
                <h2>Phase 2: CBOR Binary Encoding (63.9 MB, 1.26x, Œî1.26x)</h2>
                <div class="box">
                    <h4>Switch to binary format</h4>
                </div>
                <pre><code class="language-plaintext"># JSON (text):
{"timestamp": 1698000000}
# 25 bytes

# CBOR (binary):
A1                        # map(1 item)
  69 74696D657374616D70   # "timestamp" (9 bytes)
  1A 6536CD80             # unsigned(1698000000) (5 bytes)
# 15 bytes (40% smaller!)

# Benefits:
# - Integers stored as binary, not strings
# - Type information embedded efficiently
# - No whitespace or quotes needed
# - Still preserves all structure</code></pre>
                <p class="small-text highlight">‚úÖ 1.26x compression through binary encoding</p>
            </section>

            <!-- Phase 3: CBOR + zstd -->
            <section>
                <h2>Phase 3: CBOR + zstd Compression (3.8 MB, 21.3x, Œî16.8x)</h2>
                <div class="box">
                    <h4>Add general-purpose compression</h4>
                </div>
                <pre><code class="language-plaintext"># zstd dictionary learning discovers patterns:

Pattern 1: "system.cpu.user" (appears 10k times)
  ‚Üí Dictionary entry #1 (2 bytes to reference)

Pattern 2: "server-01" (appears 10k times)
  ‚Üí Dictionary entry #2

Pattern 3: Sequential timestamps
  ‚Üí Run-length encoding finds patterns

Pattern 4: Label structure repetition
  ‚Üí Reference previous occurrences

# Result: 63.9 MB ‚Üí 3.8 MB (16.8x additional compression!)
# Combined: 80.8 MB ‚Üí 3.8 MB (21.3x total)</code></pre>
                <p class="small-text highlight">‚úÖ Biggest single jump: 16.8x improvement from zstd!</p>
            </section>

            <!-- Phase 4: Binary Table -->
            <section>
                <h2>Phase 4: Binary Table with String Deduplication (2.8 MB, 28.9x, Œî1.36x)</h2>
                <div class="box">
                    <h4>Key Insight: String Deduplication</h4>
                </div>
                <pre><code class="language-python"># Before: Each row stores full strings
{name: "system.cpu.user", labels: {host: "server-01", dc: "us-west-1"}}
{name: "system.cpu.user", labels: {host: "server-01", dc: "us-west-1"}}
# "system.cpu.user" repeated 1000 times = 17,000 bytes

# After: Store strings once, use IDs
strings: ["system.cpu.user", "server-01", "us-west-1"]
rows: [{name_id: 0, label_ids: [1, 2]}, {name_id: 0, label_ids: [1, 2]}]
# 17 bytes + (1000 √ó 3 bytes) = 3,017 bytes

# Savings: 5.6x just from deduplication!</code></pre>
                <p class="small-text highlight">‚úÖ 28.9x total - deduplication enables better zstd compression</p>
            </section>

            <!-- Phase 5: Columnar Storage -->
            <section>
                <h2>Phase 5: Columnar Storage (2.0 MB, 40.4x, Œî1.40x)</h2>
                <div class="box">
                    <h4>Key Insight: Group Similar Data</h4>
                </div>
                <div class="two-column">
                    <div>
                        <h4>Row-oriented (Before)</h4>
                        <pre><code class="language-python">row1: {ts: 1000, val: 72.3}
row2: {ts: 1060, val: 72.4}
row3: {ts: 1120, val: 72.5}</code></pre>
                        <p class="small-text">Mixed types, poor compression</p>
                    </div>
                    <div>
                        <h4>Column-oriented (After)</h4>
                        <pre><code class="language-python">timestamps: [1000, 1060, 1120]
values:     [72.3, 72.4, 72.5]</code></pre>
                        <p class="small-text">Similar values together = better compression</p>
                    </div>
                </div>
                <p class="small-text" style="margin-top: 20px;"><strong>Why it works:</strong></p>
                <ul class="small-text">
                    <li>All timestamps together ‚Üí delta encoding applies better</li>
                    <li>All values together ‚Üí XOR/floating-point compression more effective</li>
                    <li>All string IDs together ‚Üí run-length encoding finds patterns</li>
                </ul>
                <p class="small-text highlight">‚úÖ 40.4x compression - columnar layout unlocks specialized algorithms</p>
            </section>

            <!-- Phase 6: Pattern-Aware Algorithms -->
            <section>
                <h2>Phase 6: Pattern-Aware Algorithms (1.0 MB, 79.7x, Œî1.97x)</h2>
                <div class="box danger">
                    <h4>The Breakthrough: Understand the Data!</h4>
                </div>
                <p class="small-text">Detect patterns and apply specialized compression:</p>
                <ul class="small-text">
                    <li><strong>Constant values:</strong> Store once + count (‚àû compression!)</li>
                    <li><strong>Near-constant:</strong> Base value + tiny deltas</li>
                    <li><strong>Power-of-2:</strong> Store exponents instead of values</li>
                    <li><strong>Mostly integers:</strong> Split integer/fractional parts</li>
                    <li><strong>Periodic patterns:</strong> Template + deviations</li>
                    <li><strong>Sparse data:</strong> Store only non-zero indices + values</li>
                </ul>
                <p class="highlight" style="margin-top: 20px; text-align: center;">
                    Result: 3.19 bytes per data point (vs 8 bytes original) - 79.7x compression!
                </p>
            </section>

            <section>
                <h2>Deep Dive: Near-Constant Encoding</h2>
                <div class="box">
                    <h4>Exploit Values That Rarely Change</h4>
                    <p class="small-text">Many metrics are nearly constant with tiny deviations</p>
                </div>
                <pre><code class="language-python"># CPU usage values (varies slightly around 72%):
values = [72.34567, 72.34589, 72.34612, 72.34599, 72.34601, ...]
# Raw: 1000 values √ó 8 bytes = 8,000 bytes

# Near-constant encoding:
base_value = 72.34567
deltas = [0.00000, 0.00022, 0.00045, 0.00032, 0.00034, ...]

# Deltas are tiny! Scale and store as small integers:
scaled_deltas = [0, 22, 45, 32, 34, ...]  # √ó 0.00001
# Most deltas fit in 1-2 bytes instead of 8!

# Result:
# - Base value: 8 bytes
# - 1000 deltas √ó ~1.5 bytes = 1,500 bytes
# - Total: 1,508 bytes vs 8,000 bytes original
# - Compression: 5.3x!

# Even better with zstd: deltas have patterns too!</code></pre>
            </section>

            <section>
                <h2>Deep Dive: Delta Encoding</h2>
                <div class="box">
                    <h4>Store Differences, Not Absolute Values</h4>
                </div>
                <pre><code class="language-python"># Regular timestamps:
timestamps = [1000, 1060, 1120, 1180, 1240]
# Each: 8 bytes = 40 bytes total

# Delta encoding:
first = 1000
deltas = [60, 60, 60, 60]
# first (8 bytes) + deltas (4√ó2 bytes) = 16 bytes

# Double-delta (deltas of deltas):
deltas = [60, 60, 60, 60]
delta_deltas = [0, 0, 0]  # All zeros!
# Run-length encode: "60 repeated 4 times"
# Result: 12 bytes (3x compression!)</code></pre>
            </section>

            <section>
                <h2>Metrics: Key Takeaways</h2>
                <div class="box success">
                    <h4>‚úÖ What Worked</h4>
                    <ul class="small-text">
                        <li><strong>Binary encoding</strong> - Simple, 1.3x gain</li>
                        <li><strong>Generic compression</strong> - zstd gives 21x without domain knowledge</li>
                        <li><strong>Columnar storage</strong> - Group similar data types</li>
                        <li><strong>Pattern detection</strong> - Specialized algorithms per pattern type</li>
                    </ul>
                </div>
                <div class="box" style="margin-top: 10px;">
                    <h4>üéØ The Progression</h4>
                    <p class="small-text">
                        <span class="highlight">1x</span> (JSON) ‚Üí 
                        <span class="highlight">21x</span> (+ zstd) ‚Üí 
                        <span class="highlight">40x</span> (+ columnar) ‚Üí 
                        <span class="highlight">80x</span> (+ patterns)
                    </p>
                    <p class="small-text">Each technique builds on previous work!</p>
                </div>
            </section>

            <!-- PART 3: LOGS -->
            <section class="center">
                <h1>Part 3: Logs</h1>
                <p>üìù Structured Text Compression</p>
            </section>

            <section>
                <h2>What Are Logs?</h2>
                <div class="box">
                    <h4>Semi-structured text event records</h4>
                </div>
                <pre><code class="language-log">[Thu Jun 09 06:07:04 2005] [notice] LDAP: Built with OpenLDAP LDAP SDK
[Thu Jun 09 06:07:05 2005] [error] env.createBean2(): Factory error creating vm
[Thu Jun 09 06:07:19 2005] [notice] jk2_init() Found child 2330 in scoreboard slot 0
[Thu Jun 09 06:07:20 2005] [error] [client 10.0.0.153] File does not exist: /var/www/html
[Thu Jun 09 06:07:21 2005] [error] [client 10.0.0.153] Directory index forbidden
</code></pre>
                <p class="small-text"><strong>Key characteristics:</strong></p>
                <ul class="small-text">
                    <li>Repeated templates with variable values</li>
                    <li>Variable types: timestamps, IPs, IDs, numbers, paths</li>
                    <li>Massive redundancy in structure</li>
                </ul>
            </section>

            <section>
                <h2>üìà Logs: Progressive Journey</h2>
                <div class="box">
                    <h4>We'll explore 6 compression phases</h4>
                    <p class="small-text">From plain text through advanced log-specific techniques</p>
                </div>
                <div class="box" style="margin-top: 20px;">
                    <p class="small-text"><strong>Dataset:</strong> OpenSSH server logs (655,147 lines)</p>
                    <p class="small-text"><strong>Starting point:</strong> 72.7 MB plain text</p>
                    <p class="small-text">Each phase will demonstrate new optimizations</p>
                </div>
            </section>

            <!-- Phase 1: Plain Text -->
            <section>
                <h2>Phase 1: Plain Text Baseline (72.7 MB, 1.0x)</h2>
                <div class="box">
                    <h4>Raw OpenSSH log files</h4>
                </div>
                <pre><code class="language-log">Dec 10 06:55:46 LabSZ sshd[24200]: reverse mapping checking getaddrinfo for ns.marryaldkfaczcz.com [173.234.31.186] failed - POSSIBLE BREAK-IN ATTEMPT!
Dec 10 06:55:46 LabSZ sshd[24200]: Invalid user webmaster from 173.234.31.186
Dec 10 06:55:46 LabSZ sshd[24200]: input_userauth_request: invalid user webmaster [preauth]
Dec 10 06:55:46 LabSZ sshd[24200]: pam_unix(sshd:auth): check pass; user unknown
Dec 10 06:55:46 LabSZ sshd[24200]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=173.234.31.186
Dec 10 06:55:48 LabSZ sshd[24200]: Failed password for invalid user webmaster from 173.234.31.186 port 38926 ssh2
Dec 10 06:55:48 LabSZ sshd[24200]: Connection closed by 173.234.31.186 [preauth]
Dec 10 07:02:47 LabSZ sshd[24203]: Connection closed by 212.47.254.145 [preauth]
</code></pre>
                <p class="small-text"><strong>Observations:</strong></p>
                <ul class="small-text">
                    <li>655,147 lines, each ~110 bytes average</li>
                    <li>Repeated structure: "timestamp hostname daemon[pid]: message"</li>
                    <li>Same message patterns with different variables</li>
                    <li>"Failed password for root" appears 139,818 times!</li>
                </ul>
            </section>

            <!-- Phase 2: zstd -->
            <section>
                <h2>Phase 2: Plain Text + zstd (3.0 MB, 24.5x, Œî24.5x)</h2>
                <div class="box">
                    <h4>General compression finds patterns automatically</h4>
                </div>
                <pre><code class="language-plaintext"># zstd dictionary learning discovers repeated patterns:

Pattern 1: "Dec 10 " (appears 655k times)
  ‚Üí Store once in dictionary, reference with 2 bytes

Pattern 2: " LabSZ sshd[" (appears 655k times)
  ‚Üí Dictionary entry

Pattern 3: "Failed password for root from " (appears 140k times)
  ‚Üí Dictionary entry

Pattern 4: "authentication failure" (appears 153k times)
  ‚Üí Dictionary entry

# Compression result:
Original: 72,746,715 bytes
Compressed: 2,968,978 bytes
Ratio: 24.5x</code></pre>
                <p class="small-text highlight">‚úÖ 24.5x with zero domain knowledge - impressive!</p>
            </section>

            <!-- Phase 3: Template Extraction -->
            <section>
                <h2>Phase 3: Template Extraction (2.0 MB, 36.3x, Œî1.48x)</h2>
                <div class="box danger">
                    <h4>The CLP Breakthrough: Separate Structure from Data!</h4>
                </div>
                <pre><code class="language-python"># Original log lines (3 examples):
Dec 10 06:55:48 LabSZ sshd[24200]: Failed password for root from 173.234.31.186 port 38926 ssh2
Dec 10 07:14:32 LabSZ sshd[24205]: Failed password for root from 218.65.30.43 port 54913 ssh2
Dec 10 08:03:17 LabSZ sshd[24220]: Failed password for root from 61.174.51.214 port 58389 ssh2

# CLP separates into template + variables:
Template #16: "<TIMESTAMP> LabSZ sshd[<NUM>]: Failed password for root from <IP> port <NUM> ssh2"

Variables (columnar storage):
  TIMESTAMP: ["Dec 10 06:55:48", "Dec 10 07:14:32", ...]
  NUM (pid): [24200, 24205, 24220, ...]
  IP: ["173.234.31.186", "218.65.30.43", "61.174.51.214", ...]
  NUM (port): [38926, 54913, 58389, ...]

Line-to-template mapping: [16, 16, 16, 16, 16, ...]  # Just template IDs!

# This template used 139,818 times!
Template storage: 81 bytes √ó 1 = 81 bytes
Variables: 139,818 √ó (time + pid + IP + port) ‚âà much smaller with type-aware compression
</code></pre>
            </section>

            <section>
                <h2>Phase 3: Template Statistics</h2>
                <div class="box">
                    <h4>Only 5,669 unique templates for 655,147 lines!</h4>
                </div>
                <table style="font-size: 0.55em;">
                    <thead>
                        <tr>
                            <th>Template</th>
                            <th>Count</th>
                            <th>%</th>
                            <th>Reuse</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Failed password for root from &lt;IP&gt; port &lt;NUM&gt; ssh2</td>
                            <td class="success">139,818</td>
                            <td>21.3%</td>
                            <td class="success">139,818x</td>
                        </tr>
                        <tr>
                            <td>authentication failure; ... rhost=&lt;IP&gt; user=root</td>
                            <td>139,572</td>
                            <td>21.3%</td>
                            <td>139,572x</td>
                        </tr>
                        <tr>
                            <td>Connection closed by &lt;IP&gt; [preauth]</td>
                            <td>68,958</td>
                            <td>10.5%</td>
                            <td>68,958x</td>
                        </tr>
                        <tr>
                            <td>Received disconnect from &lt;IP&gt;: &lt;NUM&gt;: Bye Bye [preauth]</td>
                            <td>46,593</td>
                            <td>7.1%</td>
                            <td>46,593x</td>
                        </tr>
                        <tr>
                            <td>PAM service(sshd) ignoring max retries; &lt;NUM&gt; &gt; &lt;NUM&gt;</td>
                            <td>37,963</td>
                            <td>5.8%</td>
                            <td>37,963x</td>
                        </tr>
                        <tr>
                            <td colspan="4" class="small-text">...and 5,664 more templates</td>
                        </tr>
                    </tbody>
                </table>
                <div class="formula" style="margin-top: 20px;">
                    Average template reuse: 655,147 lines √∑ 5,669 templates = <span class="highlight">116x per template!</span>
                </div>
            </section>

            <!-- Phase 4: Variable Encoding -->
            <section>
                <h2>Phase 4: Type-Aware Variable Encoding (1.9 MB, 38.7x, Œî1.07x)</h2>
                <div class="box">
                    <h4>Compress each variable type optimally</h4>
                </div>
                <pre><code class="language-python"># TIMESTAMP variables (655,147 occurrences):
Raw: ["Dec 10 06:55:46", "Dec 10 06:55:46", "Dec 10 06:55:48", ...]
Delta encoded:
  Base: "Dec 10 06:55:46"
  Deltas: [0, 0, 2, 1, 58, 0, ...]  # Seconds difference
  Compression: 12,447,793 bytes ‚Üí efficient storage (using numpy arrays)

# IP variables (549,454 occurrences):
Raw: ["173.234.31.186", "173.234.31.186", "212.47.254.145", ...]
Integer encoding + Dictionary:
  Convert to uint32: [2910973370, 2910973370, 3561263233, ...]
  Dictionary + indices for repeated IPs
  Compression: ~6.8 MB ‚Üí 2.2 MB (3.1x)

# NUM (port/pid) variables (1,458,375 occurrences):
Raw: [24200, 38926, 24203, 54913, 24220, 58389, ...]
Numpy array (efficient integer storage):
  Compression: Uses compact numpy dtype
  Size: 11.7 MB (efficient integer packing)

# PATH variables (11 occurrences):
Raw: ["/var/log/secure", "/etc/ssh/sshd_config", ...]
Dictionary with prefix compression: 232 bytes
</code></pre>
            </section>

            <!-- Phase 5: Smart Row Ordering -->
            <section>
                <h2>Phase 5: Smart Row Ordering (1.9 MB, 38.7x, Œî1.00x)</h2>
                <pre><code class="language-python"># Strategy: Group by template, sort within groups by time
# Before (chronological, interleaved):
Line 1000: Template 16 "Failed password for root"
Line 1001: Template 6  "Connection closed"
Line 1002: Template 16 "Failed password for root"
Line 1003: Template 21 "authentication failure"
Line 1004: Template 16 "Failed password for root"
# Poor compression - similar patterns scattered

# After (grouped by template):
Template 16: "Failed password for root"  √ó 139,818 lines
  Dec 10 06:55:48 LabSZ sshd[24200]: ... from 173.234.31.186 port 38926 ssh2
  Dec 10 07:14:32 LabSZ sshd[24205]: ... from 218.65.30.43 port 54913 ssh2
  Dec 10 08:03:17 LabSZ sshd[24220]: ... from 61.174.51.214 port 58389 ssh2
  ... (all similar logs grouped)

Template 21: "authentication failure" √ó 139,572 lines
Template 6: "Connection closed" √ó 68,958 lines

# Benefits:
# - Similar variables adjacent ‚Üí better delta encoding
# - Template IDs grouped ‚Üí better RLE compression
# - zstd finds longer matching patterns</code></pre>
            </section>

            <!-- Phase 5: The Order Preservation Cost -->
            <section>
                <h2>Phase 5: Why No Improvement?</h2>
                <div class="box danger">
                    <h4>‚ö†Ô∏è Preserving original order is expensive!</h4>
                </div>
                
                <h3 style="margin-top: 30px;">How Order Mapping Works:</h3>
                <ul>
                    <li><strong>Raw data:</strong> 655,147 uint32 indices (2.6 MB)</li>
                    <li><strong>Delta encoding:</strong> Small deltas between reordered positions</li>
                    <li><strong>Varint encoding:</strong> Small numbers use fewer bytes</li>
                    <li><strong>Zstd L22:</strong> Compresses patterns in deltas</li>
                    <li><strong>Result:</strong> 2.6 MB ‚Üí 130 KB (20x compression)</li>
                </ul>

                <p style="margin-top: 30px;"><strong>Final outcome:</strong> 1.895 MB ‚Üí 1.897 MB (0.999x) - essentially no change because the ordering overhead (130 KB) is offset by better template grouping compression.</p>
                <p><strong>Solution:</strong> Phase 6 drops order preservation to get the full benefit!</p>
            </section>

            <!-- Phase 6: Drop Order Preservation -->
            <section>
                <h2>Phase 6: Drop Order Preservation (1.77 MB, 41.2x, Œî1.07x)</h2>
                <div class="box">
                    <h4>Remove line ordering for maximum compression</h4>
                </div>
                <pre><code class="language-python"># Before (Phase 5): Preserve line numbers
{
  "templates": [...],
  "line_to_template": [16, 16, 16, 6, 21, 16, ...],  # 655,147 entries
  "variables_per_line": {
    0: {"time": "...", "pid": ..., "ip": "...", "port": ...},
    1: {"time": "...", "pid": ..., "ip": "...", "port": ...},
    ...
  }
}

# After (Phase 6): No line numbers, just templates + variables
{
  "templates": [...],
  "template_data": {
    16: {  # Template 16: 139,818 occurrences
      "times": ["Dec 10 06:55:48", ...],         # 139,818 values
      "pids": [24200, 24205, ...],               # 139,818 values
      "ips": ["173.234.31.186", ...],            # 139,818 values
      "ports": [38926, 54913, ...]               # 139,818 values
    },
    21: {  # Template 21: 139,572 occurrences
      "times": [...],  # 139,572 values
      "pids": [...],
      "ips": [...],
    },
    ...
  }
}

# Benefits:
# - No need to store 655,147 line-to-template mappings
# - Variables perfectly grouped by template
# - Maximum compression locality
# - Additional 1.07x improvement</code></pre>
            </section>

            <!-- Comparison slide -->
            <section>
                <h2>Logs: Compression Comparison</h2>
                <table style="font-size: 0.6em;">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>Format</th>
                            <th>Size</th>
                            <th>Ratio</th>
                            <th>Key Technique</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td>Plain Text</td>
                            <td class="danger">72.7 MB</td>
                            <td>1.0x</td>
                            <td>None (baseline)</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>Plain + zstd</td>
                            <td class="warning">3.0 MB</td>
                            <td class="success">24.5x</td>
                            <td>Pattern dictionary</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>Templates + zstd</td>
                            <td class="warning">2.0 MB</td>
                            <td class="success">36.3x</td>
                            <td>CLP template extraction</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>Type-aware vars</td>
                            <td class="success">1.9 MB</td>
                            <td class="success">38.7x</td>
                            <td>Delta/dict per type</td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td>Smart ordering</td>
                            <td class="success">1.9 MB</td>
                            <td class="success">38.7x</td>
                            <td>Group by template</td>
                        </tr>
                        <tr>
                            <td>6</td>
                            <td>No ordering</td>
                            <td class="success">1.77 MB</td>
                            <td class="success">41.2x</td>
                            <td>Drop line numbers</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section>
                <h2>Logs: Dataset Comparison</h2>
                <table style="font-size: 0.6em;">
                    <thead>
                        <tr>
                            <th>Dataset</th>
                            <th>Lines</th>
                            <th>Size</th>
                            <th>Templates</th>
                            <th>Reuse</th>
                            <th>Final Ratio</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Apache (small)</td>
                            <td>56,482</td>
                            <td>5.1 MB</td>
                            <td>38</td>
                            <td class="success">1,486x</td>
                            <td class="success">50.7x</td>
                        </tr>
                        <tr>
                            <td>HDFS (big)</td>
                            <td>74,859</td>
                            <td>10.5 MB</td>
                            <td>18</td>
                            <td class="success">4,159x</td>
                            <td class="warning">24.2x</td>
                        </tr>
                        <tr>
                            <td>OpenSSH (huge)</td>
                            <td>655,147</td>
                            <td>72.7 MB</td>
                            <td>5,669</td>
                            <td class="warning">116x</td>
                            <td class="success">41.2x</td>
                        </tr>
                    </tbody>
                </table>
                <div class="box" style="margin-top: 20px;">
                    <p class="small-text"><strong>Why is HDFS worse despite 4,159x template reuse?</strong></p>
                    <ul class="small-text">
                        <li><strong>High-cardinality variables:</strong> 74,859 unique block identifiers (296 KB encoded)</li>
                        <li><strong>Lots of numbers:</strong> 141,631 numeric values (566 KB)</li>
                        <li><strong>Many unique paths:</strong> 58,747 file paths (1.22 MB)</li>
                        <li><strong>Even with timestamp delta encoding:</strong> 74,859 timestamps ‚Üí 145 KB (6.7x, but still significant)</li>
                        <li><strong>Total variable overhead:</strong> 3.9 MB uncompressed (despite only 18 templates!)</li>
                    </ul>
                    <p class="small-text"><strong>Key insight:</strong> Template reuse alone isn't enough - variable types, cardinality, and uniqueness dominate!</p>
                </div>
            </section>

            <section>
                <h2>Logs: Key Takeaways</h2>
                <div class="box success">
                    <h4>‚úÖ CLP Algorithm is the Star</h4>
                    <ul class="small-text">
                        <li><strong>Template extraction:</strong> Separating structure from data enables massive compression</li>
                        <li><strong>Template reuse:</strong> Key metric - OpenSSH achieves 116x average reuse (5,669 templates for 655k lines)</li>
                        <li><strong>Type-aware encoding:</strong> Each variable type compressed optimally (3-6x per type)</li>
                        <li><strong>Ordering optimizations:</strong> Grouping similar data improves compression locality</li>
                    </ul>
                </div>
                <div class="box" style="margin-top: 10px;">
                    <h4>üéØ The Progression</h4>
                    <p class="small-text">
                        <span class="highlight">1x</span> (plain) ‚Üí 
                        <span class="highlight">24.5x</span> (+ zstd) ‚Üí 
                        <span class="highlight">36.3x</span> (+ templates) ‚Üí 
                        <span class="highlight">38.7x</span> (+ type-aware) ‚Üí 
                        <span class="highlight">41.2x</span> (+ optimizations)
                    </p>
                </div>
            </section>
            <!-- PART 4: TRACES -->
            <section class="center">
                <h1>Part 4: Traces</h1>
                <p>üîç Distributed Execution Compression</p>
            </section>

            <section>
                <h2>What Are Traces?</h2>
                <div class="box">
                    <h4>Distributed request execution flows</h4>
                    <p class="small-text">Track a request across multiple microservices</p>
                </div>
                <pre class="small-text"><code>User Request ‚Üí api-gateway (50ms)
                  ‚Üì
               user-service (30ms)
                  ‚Üì
               auth-service (20ms)
                  ‚Üì
               auth-db (10ms)</code></pre>
                <p class="small-text"><strong>Each "span" contains:</strong></p>
                <ul class="small-text">
                    <li>trace_id (links all spans in one request)</li>
                    <li>span_id + parent_span_id (tree structure)</li>
                    <li>service_name, operation_name</li>
                    <li>start_time, end_time (nanoseconds)</li>
                    <li>tags, logs, status</li>
                </ul>
            </section>

            <section>
                <h2>üìà Traces: Progressive Journey</h2>
                <div class="box">
                    <h4>We'll explore 5 compression phases</h4>
                    <p class="small-text">From JSON through trace structure exploitation</p>
                </div>
                <div class="box" style="margin-top: 20px;">
                    <p class="small-text"><strong>Dataset:</strong> 50,000 traces, 141,531 spans, 12 services</p>
                    <p class="small-text"><strong>Starting point:</strong> 71.1 MB NDJSON</p>
                    <p class="small-text">Each phase will reveal new structural optimizations</p>
                </div>
            </section>

            <!-- Phase 0: Original JSON -->
            <section>
                <h2>Phase 0: Original JSON (71.1 MB)</h2>
                <div class="box">
                    <h4>OpenTelemetry-style distributed trace data</h4>
                </div>
                <pre><code class="language-json">{
  "trace_id": "trace-00000001-df734723",
  "spans": [{
    "trace_id": "trace-00000001-df734723",
    "span_id": "666ffb28a8ca45d7",
    "parent_span_id": null,
    "operation_name": "authenticate",
    "service_name": "api-gateway",
    "start_time": 1761416099523944960,
    "end_time": 1761416099585944960,
    "duration": 62000000,
    "tags": {
      "service.name": "api-gateway",
      "http.method": "DELETE",
      "http.status_code": 201,
      "user.id": "user-2256"
    },
    "logs": [],
    "status_code": 0
  }]
}</code></pre>
                <p class="small-text">‚ùå Verbose: Every field spelled out, repeated service/operation names</p>
            </section>

            <!-- Phase 1: NDJSON -->
            <section>
                <h2>Phase 1: NDJSON Baseline (71.1 MB, 1.0x)</h2>
                <div class="box">
                    <h4>One span per line (newline-delimited JSON)</h4>
                </div>
                <pre><code class="language-json">{"trace_id":"trace-00000001-df734723","span_id":"666ffb28a8ca45d7",...}
{"trace_id":"trace-00000001-df734723","span_id":"8a89dc3a1a204434",...}
{"trace_id":"trace-00000001-df734723","span_id":"b2deb5edd9a74b4f",...}
{"trace_id":"trace-00000002-a9549627","span_id":"868b3925a9374271",...}</code></pre>
                <p class="small-text"><strong>Characteristics:</strong></p>
                <ul class="small-text">
                    <li>141,531 spans = 141,531 lines</li>
                    <li>Text-based, human-readable</li>
                    <li>Easy to process line-by-line</li>
                    <li>Repeated keys: "trace_id", "span_id", "service_name", etc.</li>
                </ul>
                <p class="small-text highlight">‚úÖ Baseline established: 71.1 MB</p>
            </section>

            <!-- Phase 2: CBOR -->
            <section>
                <h2>Phase 2: CBOR Binary (39.6 MB, 1.79x, Œî1.79x)</h2>
                <div class="box">
                    <h4>Binary encoding with type tags</h4>
                </div>
                <pre><code class="language-plaintext"># JSON (text):
{"trace_id": "trace-00000001-df734723", "span_id": "666ffb28a8ca45d7"}
# 71 bytes

# CBOR (binary):
A2                        # map(2 items)
  68 74726163655F6964     # "trace_id" (8 bytes)
  78 1C 74726163652D...   # "trace-00000001-df734723" (28 bytes)
  67 7370616E5F6964       # "span_id" (7 bytes)
  70 363636666662323...   # "666ffb28a8ca45d7" (16 bytes)
# 39 bytes (44% smaller!)

# Still verbose: All keys/values in every span
# But binary integers, efficient string encoding</code></pre>
                <p class="small-text highlight">‚úÖ 1.79x compression through binary encoding</p>
            </section>

            <!-- Phase 3: CBOR + zstd -->
            <section>
                <h2>Phase 3: CBOR + zstd (5.6 MB, 12.6x, Œî7.04x)</h2>
                <div class="box">
                    <h4>General-purpose compression on binary data</h4>
                </div>
                <pre><code class="language-plaintext"># zstd identifies patterns:
Pattern 1: "trace_id" appears 141,531 times
  ‚Üí Dictionary entry #1 (4 bytes to reference)

Pattern 2: "api-gateway" appears 50,000 times
  ‚Üí Dictionary entry #2

Pattern 3: Sequential timestamps
  ‚Üí Run-length encoding

Pattern 4: Repeated tag structures
  ‚Üí Reference previous occurrence

# Result: 39.6 MB ‚Üí 5.6 MB (7x additional compression)</code></pre>
                <p class="small-text highlight">‚úÖ 12.6x total compression - biggest single jump!</p>
            </section>

            <!-- Phase 4: Span Relationships -->
            <section>
                <h2>Phase 4: Span Relationships (2.3 MB, 30.5x, Œî2.43x)</h2>
                <div class="box danger">
                    <h4>The Breakthrough: Exploit Trace Structure!</h4>
                </div>
                <pre><code class="language-python"># Before: Every span stores full identifiers
{
  "trace_id": "trace-00000001-df734723",  # 28 bytes
  "span_id": "666ffb28a8ca45d7",          # 16 bytes
  "parent_span_id": "8a89dc3a1a204434",   # 16 bytes
  "service_name": "api-gateway",          # 11 bytes
  "operation_name": "authenticate"        # 12 bytes
}

# After: Dictionary + sequential IDs
{
  "services": ["api-gateway", "user-service", ...],  # 12 strings total
  "operations": ["authenticate", "route_request", ...],  # 12 strings
  "traces": [
    {
      "trace_id": "trace-00000001-df734723",
      "spans": [
        {"svc": 0, "op": 0, "parent": -1, "duration": 62000000},  # Root
        {"svc": 1, "op": 2, "parent": 0, "duration": 97000000},   # Child of 0
        {"svc": 2, "op": 5, "parent": 1, "duration": 31000000}    # Child of 1
      ]
    }
  ]
}</code></pre>
            </section>

            <section>
                <h2>Phase 4: Relationship Compression Details</h2>
                <div class="two-column small-text">
                    <div>
                        <h4>Service Deduplication</h4>
                        <pre><code># Before:
"api-gateway" √ó 50,000 = 550 KB
"user-service" √ó 8,457 = 93 KB
Total: ~1.5 MB

# After:
12 service names = 150 bytes
50K IDs √ó 1 byte = 50 KB
Total: 50 KB (30x!)</code></pre>
                    </div>
                    <div>
                        <h4>Parent Relationships</h4>
                        <pre><code># Before:
UUID parent_span_id √ó 141K
= 2.3 MB

# After:
Sequential index √ó 141K
= 141 KB (16x!)

Root: parent = -1
Others: parent = 0-9</code></pre>
                    </div>
                </div>
                <div class="box" style="margin-top: 20px;">
                    <h4>Timestamp Delta Encoding</h4>
                    <pre><code class="small-text"># Root span: 1761416099523944960 (store full timestamp)
# Child span 1: +10,000,000 (10ms later, store delta)
# Child span 2: +20,000,000 (20ms after child 1)
# Result: 2-3 bytes per delta vs 8 bytes absolute</code></pre>
                </div>
                <p class="small-text highlight" style="text-align: center;">‚úÖ 30.5x compression through structure exploitation!</p>
            </section>

            <!-- Phase 5: Columnar Storage -->
            <section>
                <h2>Phase 5: Columnar Storage (1.9 MB, 37.3x, Œî1.22x)</h2>
                <div class="box">
                    <h4>Separate data by type for better compression</h4>
                </div>
                <pre><code class="language-python"># Before (row-oriented):
span1: {duration: 62000000, status: 0, parent: -1}
span2: {duration: 97000000, status: 0, parent: 0}
span3: {duration: 31000000, status: 0, parent: 1}
# Mixed types, poor compression locality

# After (columnar):
{
  "durations": [62000000, 97000000, 31000000, ...],  # All similar values
  "status_codes": [0, 0, 0, 0, 1, 0, ...],           # Mostly zeros
  "parent_indices": [-1, 0, 1, 2, 1, 0, ...],        # Small integers
  "span_positions": [4, 9, 1, 1, 1, 9, 9, ...]       # Spans per trace
}

# Compressed columnar arrays:
# - durations: 708KB ‚Üí 308KB (delta encoding + zstd)
# - status_codes: 141KB ‚Üí 4KB (run-length: mostly zeros!)
# - parent_indices: 141KB ‚Üí 11KB (small integers compress well)</code></pre>
                <p class="small-text highlight">‚úÖ 37.3x total compression - columnar wins!</p>
            </section>

            <!-- Comparison slide -->
            <section>
                <h2>Traces: Compression Comparison</h2>
                <table style="font-size: 0.6em;">
                    <thead>
                        <tr>
                            <th>Phase</th>
                            <th>Format</th>
                            <th>Size</th>
                            <th>Ratio</th>
                            <th>Key Technique</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>Original JSON</td>
                            <td class="danger">71.1 MB</td>
                            <td>1.0x</td>
                            <td>None (baseline)</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>NDJSON</td>
                            <td class="danger">71.1 MB</td>
                            <td>1.0x</td>
                            <td>Line-delimited format</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>CBOR</td>
                            <td class="warning">39.6 MB</td>
                            <td>1.79x</td>
                            <td>Binary encoding</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>CBOR + zstd</td>
                            <td class="warning">5.6 MB</td>
                            <td class="success">12.6x</td>
                            <td>Dictionary compression</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>Relationships</td>
                            <td class="success">2.3 MB</td>
                            <td class="success">30.5x</td>
                            <td>Service dict + sequential IDs</td>
                        </tr>
                        <tr>
                            <td>5</td>
                            <td>Columnar</td>
                            <td class="success">1.9 MB</td>
                            <td class="success">37.3x</td>
                            <td>Type-grouped arrays</td>
                        </tr>
                    </tbody>
                </table>
                <div class="box" style="margin-top: 20px;">
                    <p class="small-text"><strong>From 71.1 MB ‚Üí 1.9 MB with structured exploitation!</strong></p>
                    <p class="small-text">Dataset: 50,000 traces √ó 2.8 avg spans = 141,531 total spans</p>
                </div>
            </section>

            <!-- Key Takeaways -->
            <section>
                <h2>Traces: Key Takeaways</h2>
                <div class="box success">
                    <h4>‚úÖ Structure Exploitation Wins</h4>
                    <ul class="small-text">
                        <li><strong>Service topology:</strong> 12 services across 141K spans ‚Üí 22x deduplication</li>
                        <li><strong>Parent-child relationships:</strong> Sequential IDs vs UUIDs ‚Üí 16x compression</li>
                        <li><strong>Timestamp locality:</strong> Delta from root ‚Üí 2-4x compression</li>
                        <li><strong>Columnar arrays:</strong> Group similar types ‚Üí 1.2x additional improvement</li>
                    </ul>
                </div>
                <div class="box" style="margin-top: 10px;">
                    <h4>üéØ The Progression</h4>
                    <p class="small-text">
                        <span class="highlight">1x</span> (NDJSON) ‚Üí 
                        <span class="highlight">1.8x</span> (+ binary) ‚Üí 
                        <span class="highlight">12.6x</span> (+ zstd) ‚Üí 
                        <span class="highlight">30.5x</span> (+ relationships) ‚Üí 
                        <span class="highlight">37.3x</span> (+ columnar)
                    </p>
                </div>
                <div class="box warning" style="margin-top: 10px;">
                    <h4>üìä Format Choice Matters</h4>
                    <p class="small-text">Relationship format for storage, Columnar format for analytics</p>
                </div>
            </section>

            <!-- PART 5: REALITY CHECK -->
            <section class="center">
                <h1>Part 5: Reality Check</h1>
                <p>‚öñÔ∏è Trade-offs & Practical Considerations</p>
            </section>

            <section>
                <h2>‚ö†Ô∏è The Compression Trilemma</h2>
                <div class="box danger">
                    <h4>You Can't Optimize Everything!</h4>
                </div>
                <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin-top: 20px;">
                    <div class="box">
                        <h4>üíæ Storage Size</h4>
                        <p class="small-text">Minimize disk usage</p>
                        <p class="success small-text">‚úÖ Focus of this project</p>
                    </div>
                    <div class="box">
                        <h4>‚ö° Ingest Speed</h4>
                        <p class="small-text">Fast data writing</p>
                        <p class="warning small-text">‚ö†Ô∏è CPU cost per write</p>
                    </div>
                    <div class="box">
                        <h4>üîç Query Speed</h4>
                        <p class="small-text">Fast data reading</p>
                        <p class="warning small-text">‚ö†Ô∏è Decompression overhead</p>
                    </div>
                </div>
                <p class="highlight" style="text-align: center; margin-top: 20px;">
                    Not always, but very often tradeoff desicions have to be made - optimizing one hurts the others
                </p>
            </section>

            <section>
                <h2>üí∞ Real-World Trade-offs</h2>
                <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin-top: 20px;">
                    <div class="box">
                        <h4>üíæ Optimize Storage</h4>
                        <p class="small-text"><strong>Analyze statistics, pick best algorithm</strong></p>
                        <p class="small-text" style="margin-top: 10px;"><em>Example:</em> Parquet - auto-selects dictionary/RLE/bit-packing per column based on cardinality and patterns</p>
                        <p class="danger small-text" style="margin-top: 10px;"><strong>Cost:</strong> Slow ingest & queries</p>
                    </div>
                    <div class="box">
                        <h4>‚ö° Optimize Ingest Speed</h4>
                        <p class="small-text"><strong>Write append-only, compress in background</strong></p>
                        <p class="small-text" style="margin-top: 10px;"><em>Example:</em> Grafana Loki - only lightweight general compression, no columnarization, no merging of chunks</p>
                        <p class="danger small-text" style="margin-top: 10px;"><strong>Cost:</strong> Higher storage, write amplification</p>
                    </div>
                    <div class="box">
                        <h4>üîç Optimize Query Speed</h4>
                        <p class="small-text"><strong>Build indexes to skip decompression</strong></p>
                        <p class="small-text" style="margin-top: 10px;"><em>Example:</em> Elasticsearch inverted indexes - skip 99% of documents without scanning</p>
                        <p class="danger small-text" style="margin-top: 10px;"><strong>Cost:</strong> 5-15% storage overhead</p>
                    </div>
                </div>
                <p class="small-text" style="margin-top: 20px; text-align: center;">
                    <strong>Key insight:</strong> Production systems use <span class="highlight">tiered storage</span> - different techniques for hot (recent), warm (weeks), and cold (archive) data
                </p>
            </section>

            <section>
                <h2>üè≠ Production System Examples</h2>
                <div class="box">
                    <h4>Prometheus (Metrics)</h4>
                    <ul class="small-text">
                        <li>Uses XOR compression (Gorilla algorithm) + delta encoding</li>
                        <li>Compression: ~10-20x (balanced approach)</li>
                        <li>Query speed: Milliseconds for recent data</li>
                        <li>Trade-off: Moderate compression for fast queries</li>
                    </ul>
                </div>
                <div class="box" style="margin-top: 10px;">
                    <h4>Elasticsearch (Logs)</h4>
                    <ul class="small-text">
                        <li>Uses Lucene inverted indexes + LZ4/DEFLATE compression</li>
                        <li>Compression: ~5-15x (optimized for search speed)</li>
                        <li>Query speed: Milliseconds with skip lists and indexes</li>
                        <li>Trade-off: Lower compression for fast full-text search</li>
                    </ul>
                </div>
                <div class="box" style="margin-top: 10px;">
                    <h4>Jaeger/Tempo (Traces)</h4>
                    <ul class="small-text">
                        <li>Use Parquet columnar format for storage</li>
                        <li>Compression: 10-30x depending on data</li>
                        <li>Trade-off: Optimized for querying by service/operation</li>
                    </ul>
                </div>
            </section>

            <section>
                <h2>üéì Key Lessons Learned</h2>
                <div class="box success">
                    <h4>‚úÖ Domain Knowledge is Powerful</h4>
                    <p class="small-text">Understanding data characteristics enables <strong>order of magnitude</strong> better compression than generic algorithms alone</p>
                </div>
                <div class="box">
                    <h4>üìê The Compression Hierarchy</h4>
                    <ol class="small-text">
                        <li><strong>Binary encoding</strong> - Easy win, 1.3x</li>
                        <li><strong>Generic compression</strong> - zstd gives 10-30x baseline</li>
                        <li><strong>Structure optimization</strong> - Deduplication, columnar: +2-3x</li>
                        <li><strong>Domain-specific algorithms</strong> - Pattern-aware: +2-4x</li>
                    </ol>
                </div>
                <div class="box warning" style="margin-top: 10px;">
                    <h4>‚ö†Ô∏è No Free Lunch</h4>
                    <p class="small-text">Higher compression = Higher CPU cost. Choose based on your <strong>access patterns</strong> and <strong>scale</strong>.</p>
                </div>
            </section>

            <section>
                <h2>üî¨ Try It Yourself!</h2>
                <div class="box">
                    <h4>The squeezed-signals Repository</h4>
                    <p class="small-text">github.com/flash1293/squeezed-signals</p>
                </div>
                <pre><code class="language-bash"># Clone and set up
git clone https://github.com/flash1293/squeezed-signals.git
cd squeezed-signals
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Try metrics compression
cd metrics
python main.py --size small

# Try logs compression  
cd ../logs
python main.py --size small

# Try traces compression
cd ../traces
python main.py --size small
</code></pre>
            </section>

            <!-- CONCLUSION -->
            <section class="center">
                <h1>Summary</h1>
                <div class="box" style="margin-top: 40px;">
                    <h3>Compression Achievements</h3>
                    <ul style="font-size: 0.9em;">
                        <li>üìä <strong>Metrics:</strong> 84 MB ‚Üí 1 MB (79.7x) via pattern-aware algorithms</li>
                        <li>üìù <strong>Logs:</strong> 72.7 MB ‚Üí 1.77 MB (41.2x) via template extraction (CLP)</li>
                        <li>üîç <strong>Traces:</strong> 71.1 MB ‚Üí 1.9 MB (37.3x) via relationship encoding</li>
                    </ul>
                </div>
                <div class="box success" style="margin-top: 30px;">
                    <h4>The Universal Principle</h4>
                    <p><strong>Understand your data ‚Üí Apply specialized techniques ‚Üí Compound with general compression</strong></p>
                </div>
            </section>

            <section class="center">
                <h1>Questions?</h1>
                <p style="margin-top: 50px;">üóúÔ∏è github.com/flash1293/squeezed-signals</p>
                <p style="margin-top: 30px;" class="small-text">Press <kbd>?</kbd> for keyboard shortcuts</p>
            </section>

        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/notes/notes.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/plugin/highlight/highlight.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            controls: false,
            progress: true,
            center: true,
            transition: 'slide',
            width: 1200,
            height: 920,
            margin: 0.04,
            plugins: [ RevealHighlight, RevealNotes ]
        });
    </script>
</body>
</html>
